## <div align="center">网络构成</div>
在[基于KNN的字体反爬模型](https://github.com/Yakuho/DealFontCrawler)完成标准的字体文件分类问题后，为了想要更加具有鲁棒性能的模型，
于是考虑了使用神经网络模型。在CV方向中，模型常常使用卷积层和全连接层的搭建用于处理图像信息。一开始，想用字体文件的坐标，用于点亮图片的像素点，
使用卷积去提取特征点从而完成任务。但是这样做计算量花费并不少，并且每个坐标点相对于图片整体来说，是小目标。在提取特征的时候很容易会被“稀释”掉，
使用卷积的念头便放弃了。再者，每个字的坐标向量“深度”并不一致，如A字的由198个坐标组成，则A坐标向量为(198, 2)；B字的由38个坐标组成，
则B坐标向量为(38, 2)。这就并不能规范好一个相同尺寸的权重向量w，从而对向量进行特征提取(即仅用全连接层搭建)，这让人很是头疼。

在NLP方向中，它们常常使用RNN去对字符向量、视频帧、语音信号进行预测，它们和坐标向量都有一个共性——就是变长度。就是其“深度”未必是一致的。使用RNN
的思想，就能使用一系列的权重向量w去解决问题了，于是乎模型采用的LSTM+FC结构。

## <div align="center">怎么对字体数据进行处理</div>

模型问题解决好了，字体数据怎么处理呢？通过观察发现，字符整体具有以下的性质

1. 相对不变性。如“曰”和“日”两字，在基于中心坐标点，四角位坐标有用于区分的比例关系
2. 平移不变性。相对位置与绝对位置的转换并不会影响字体本身
3. 可缩放性。按照相对比例缩放并不会影响字体本身

<details open>
<summary>训练数据的处理</summary>

针对以上的性质，可以对字符进行一下的处理，让字符坐标归一化
1. 相对不变性

    对字符而言的，无论字符在坐标轴的哪个位置，其每个坐标点基于字符的中心点而言其相对位置基本变化不大，所以先算出每个字符的中心点坐标。

2. 平移不变性

    字体在坐标轴的哪个位置都不影响其表达的意思，便可使用中心坐标将整个字体坐标相减，将字体坐标拉到坐标轴原点。
    
3. 可缩放性

    到这步得到了中心位置都是在原点出发的字符坐标。若使用高度和宽度分别归一化，这会导致有缺陷可能，如"一" "1"两个
    坐标归一化后非常相似，这显然不是想要的结果。故使用max(height, width)进行归一化

</details>
